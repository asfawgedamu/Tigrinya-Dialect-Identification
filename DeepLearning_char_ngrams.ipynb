{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asfawgedamu/Tigrinya-Dialect-Identification/blob/main/DeepLearning_char_ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ewk9fvtofG9n",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ewk9fvtofG9n"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import ngrams\n",
        "\n",
        "# Import TensorFlow and Keras directly\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical  # Corrected import\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "random.seed(42)\n",
        "\n",
        "# Put the hyperparameters at the top like this to make it easier to change and edit.\n",
        "\n",
        "# Vectorization parameters\n",
        "max_features = 20000  # Limit on the number of features\n",
        "embedding_dim = 64  # Dimension of the embedding vectors\n",
        "max_length = 500  # Limit on the length of text sequences\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "training_portion = .8\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "from google.colab import files\n",
        "\n",
        "# Create document\n",
        "doc = Document()\n",
        "\n",
        "# Add main heading\n",
        "main_heading = doc.add_heading('üéâ LinkedIn Post: \"How to Automate Birthday Wishes Like a Data Wizard (Feat. My Birthday SQL Party!)\"', 0)\n",
        "main_heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "\n",
        "# Add subtitle\n",
        "doc.add_paragraph('Because why celebrate normally when you can over-engineer it with databases?', style='IntenseQuote')\n",
        "\n",
        "# Add section headers with formatting\n",
        "def add_section(title, content, code_blocks=[], tables=[]):\n",
        "    doc.add_heading(title, level=1)\n",
        "    doc.add_paragraph(content)\n",
        "\n",
        "    for code in code_blocks:\n",
        "        p = doc.add_paragraph()\n",
        "        p.add_run(code).font.name = 'Courier New'\n",
        "\n",
        "    for table_data in tables:\n",
        "        table = doc.add_table(rows=1, cols=len(table_data['headers']))\n",
        "        table.style = 'Table Grid'\n",
        "\n",
        "        # Add headers\n",
        "        hdr_cells = table.rows[0].cells\n",
        "        for i, header in enumerate(table_data['headers']):\n",
        "            hdr_cells[i].text = header\n",
        "\n",
        "        # Add rows\n",
        "        for row in table_data['rows']:\n",
        "            row_cells = table.add_row().cells\n",
        "            for i, value in enumerate(row):\n",
        "                row_cells[i].text = str(value)\n",
        "\n",
        "# Add Act 1: SQL Query\n",
        "add_section(\n",
        "    \"üöÄ Act 1: The 'Cake or Error?' SQL Query\",\n",
        "    \"Goal: Fetch birthdays while dodging grumpy coworkers.\",\n",
        "    code_blocks=[\n",
        "        \"\"\"SELECT CONCAT(\n",
        "    'üéÇ Happy Birthday, ', first_name, ' ', last_name,\n",
        "    '! Your ', TIMESTAMPDIFF(YEAR, birth_date, CURDATE()),\n",
        "    'th lap around the sun deserves ',\n",
        "    ELT(RAND()*4+1, 'cake üç∞', 'pizza üçï', 'SQL jokes üòú', 'a raise (just kidding) üí∏')\n",
        ") AS message\n",
        "FROM employees\n",
        "WHERE DATE_FORMAT(birth_date, '%m-%d') = DATE_FORMAT(NOW(), '%m-%d')\n",
        "AND is_grumpy = FALSE; -- Sorry, Grumpy Cat üê±\"\"\"\n",
        "    ],\n",
        "    tables=[\n",
        "        {\n",
        "            'headers': ['user_id', 'first_name', 'last_name', 'birth_date', 'is_grumpy'],\n",
        "            'rows': [\n",
        "                (1, 'Asfaw', 'Gedamu', '1990-08-25', 'FALSE'),\n",
        "                (666, 'Grumpy', 'Cat', '2012-04-04', 'TRUE')\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add Act 2: Trigger System\n",
        "add_section(\n",
        "    \"ü§ñ Act 2: The 'Trigger-Happy HR' Audit System\",\n",
        "    \"Goal: Log when HR ~accidentally~ changes your birth year.\",\n",
        "    code_blocks=[\n",
        "        \"\"\"DELIMITER $$\n",
        "CREATE TRIGGER birthdate_change_detector\n",
        "AFTER UPDATE ON employees\n",
        "FOR EACH ROW\n",
        "BEGIN\n",
        "  IF OLD.birth_date != NEW.birth_date THEN\n",
        "    INSERT INTO audit_log (message) VALUES (\n",
        "      CONCAT('HR changed ', NEW.first_name, '‚Äôs birthdate. Suspicions: ', RAND()*100, '%')\n",
        "    );\n",
        "  END IF;\n",
        "END$$\n",
        "DELIMITER ;\"\"\"\n",
        "    ],\n",
        "    tables=[\n",
        "        {\n",
        "            'headers': ['Audit Log Message'],\n",
        "            'rows': [\n",
        "                ['HR changed Asfaw‚Äôs birthdate. Suspicions: 42.69%']\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add Act 3: Stored Procedure\n",
        "add_section(\n",
        "    \"‚è∞ Act 3: The 'Birthday Butler' Stored Procedure\",\n",
        "    \"Daily check for birthdays (like a polite robot).\",\n",
        "    code_blocks=[\n",
        "        \"\"\"CREATE PROCEDURE DailyBirthdayCheck()\n",
        "BEGIN\n",
        "  DECLARE today VARCHAR(5);\n",
        "  SET today = DATE_FORMAT(NOW(), '%m-%d');\n",
        "\n",
        "  SELECT CONCAT('üéâ ', first_name, ' ', last_name) AS birthday_kid\n",
        "  FROM employees\n",
        "  WHERE DATE_FORMAT(birth_date, '%m-%d') = today\n",
        "  AND is_grumpy = FALSE;\n",
        "END;\"\"\",\n",
        "        \"\"\"# Cron Job (runs daily at 9 AM ‚òï)\n",
        "0 9 * * * mysql -u root -p\"secret\" -e \"CALL DailyBirthdayCheck();\" \"\"\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add Gratitude Section\n",
        "add_section(\n",
        "    \"üíå Act 4: Gratitude Engine for LinkedIn Squad\",\n",
        "    \"\",\n",
        "    tables=[\n",
        "        {\n",
        "            'headers': ['Sender', 'Time', 'Message'],\n",
        "            'rows': [\n",
        "                ['Alo Olatokunboh Akin', '12:12 PM', 'Wishing you a very happy birthday...'],\n",
        "                ['Ram Tippireddy', '12:00 PM', 'Wishing you a very happy birthday!'],\n",
        "                # Add all other messages here\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Save and download\n",
        "doc.save('birthday_post.docx')\n",
        "files.download('birthday_post.docx')\n",
        "\n",
        "print(\"üéâ Document downloaded successfully! Happy birthday! ü•≥\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0bX0z-Pgu36m",
        "outputId": "c42821d1-cb9f-46d2-c781-3fa1c70825c3"
      },
      "id": "0bX0z-Pgu36m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting lxml>=3.1.0 (from python-docx)\n",
            "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lxml, python-docx\n",
            "Successfully installed lxml-5.3.0 python-docx-1.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/docx/styles/styles.py:130: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
            "  return self._get_style_id_from_style(self[style_name], style_type)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5bb9a41e-71d9-4082-89dc-711b6df39bb6\", \"birthday_post.docx\", 38148)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Document downloaded successfully! Happy birthday! ü•≥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the python-docx library\n",
        "!pip install python-docx\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "from docx import Document\n",
        "from google.colab import files\n",
        "\n",
        "# Step 3: Create a new Document\n",
        "doc = Document()\n",
        "\n",
        "# Step 4: Add a title\n",
        "doc.add_heading('Automating Birthday Greetings with SQL and Python', level=1)\n",
        "\n",
        "# Step 5: Add introduction\n",
        "doc.add_paragraph(\n",
        "    \"In this document, we'll explore how companies can automate birthday greetings \"\n",
        "    \"using SQL stored procedures and scheduling tools like cron. This ensures employees \"\n",
        "    \"feel valued and appreciated on their special day.\"\n",
        ")\n",
        "\n",
        "# Step 6: Add a section for Automating Birthday Greetings\n",
        "doc.add_heading('1. Automating Birthday Greetings', level=2)\n",
        "\n",
        "# Step 7: Add subsection for Sample Input Data\n",
        "doc.add_heading('A. Sample Input Data', level=3)\n",
        "doc.add_paragraph(\n",
        "    \"Consider a table named 'users' with the following structure:\"\n",
        ")\n",
        "\n",
        "# Step 8: Add a table for sample input data\n",
        "table = doc.add_table(rows=1, cols=4)\n",
        "hdr_cells = table.rows[0].cells\n",
        "hdr_cells[0].text = 'user_id'\n",
        "hdr_cells[1].text = 'first_name'\n",
        "hdr_cells[2].text = 'last_name'\n",
        "hdr_cells[3].text = 'date_of_birth'\n",
        "sample_data = [\n",
        "    (1, 'John', 'Doe', '1990-01-31'),\n",
        "    (2, 'Jane', 'Smith', '1985-02-15'),\n",
        "    (3, 'Asfaw', 'Gedamu', '1975-01-31')\n",
        "]\n",
        "for user_id, first_name, last_name, dob in sample_data:\n",
        "    row_cells = table.add_row().cells\n",
        "    row_cells[0].text = str(user_id)\n",
        "    row_cells[1].text = first_name\n",
        "    row_cells[2].text = last_name\n",
        "    row_cells[3].text = dob\n",
        "\n",
        "# Step 9: Add subsection for Stored Procedure\n",
        "doc.add_heading('B. Stored Procedure', level=3)\n",
        "doc.add_paragraph(\n",
        "    \"We'll create a stored procedure that identifies users whose birthday is today and returns their names:\"\n",
        ")\n",
        "stored_procedure_code = \"\"\"\n",
        "DELIMITER //\n",
        "\n",
        "CREATE PROCEDURE GetTodaysBirthdays()\n",
        "BEGIN\n",
        "    SELECT CONCAT('Happy Birthday, ', first_name, ' ', last_name, '!') AS birthday_message\n",
        "    FROM users\n",
        "    WHERE DATE_FORMAT(date_of_birth, '%m-%d') = DATE_FORMAT(CURDATE(), '%m-%d');\n",
        "END //\n",
        "\n",
        "DELIMITER ;\n",
        "\"\"\"\n",
        "doc.add_paragraph(stored_procedure_code, style='Code')\n",
        "\n",
        "# Step 10: Add subsection for Scheduling with Cron\n",
        "doc.add_heading('C. Scheduling with Cron', level=3)\n",
        "doc.add_paragraph(\n",
        "    \"To automate the execution of this procedure daily, we can use a cron job that runs a script at a specified time. \"\n",
        "    \"Assuming we're using MySQL, the script ('birthday_wishes.sh') might look like this:\"\n",
        ")\n",
        "cron_script = \"\"\"\n",
        "#!/bin/bash\n",
        "mysql -u [username] -p[password] -e \"CALL GetTodaysBirthdays();\" > birthday_messages.txt\n",
        "\"\"\"\n",
        "doc.add_paragraph(cron_script, style='Code')\n",
        "doc.add_paragraph(\n",
        "    \"Make the script executable:\"\n",
        ")\n",
        "chmod_command = \"chmod +x birthday_wishes.sh\"\n",
        "doc.add_paragraph(chmod_command, style='Code')\n",
        "doc.add_paragraph(\n",
        "    \"Then, set up a cron job to run the script daily at a specific time (e.g., 9 AM):\"\n",
        ")\n",
        "cron_job = \"0 9 * * * /path/to/birthday_wishes.sh\"\n",
        "doc.add_paragraph(cron_job, style='Code')\n",
        "\n",
        "# Step 11: Add subsection for Sample Output\n",
        "doc.add_heading('D. Sample Output', level=3)\n",
        "doc.add_paragraph(\n",
        "    \"If today is January 31st, the output ('birthday_messages.txt') would be:\"\n",
        ")\n",
        "sample_output = \"\"\"\n",
        "Happy Birthday, John Doe!\n",
        "Happy Birthday, Asfaw Gedamu!\n",
        "\"\"\"\n",
        "doc.add_paragraph(sample_output, style='Code')\n",
        "\n",
        "# Step 12: Add a section for Expressing Gratitude for Birthday Wishes\n",
        "doc.add_heading('2. Expressing Gratitude for Birthday Wishes', level=2)\n",
        "doc.add_paragraph(\n",
        "    \"To acknowledge and thank connections who have sent birthday wishes, we can analyze the messages received.\"\n",
        ")\n",
        "\n",
        "# Step 13: Add subsection for Sample Input Data (LinkedIn Messages Table)\n",
        "doc.add_heading('A. Sample Input Data (LinkedIn Messages Table)', level=3)\n",
        "linkedin_table = doc.add_table(rows=1, cols=3)\n",
        "hdr_cells = linkedin_table.rows[0].cells\n",
        "hdr_cells[0].text = 'sender_name'\n",
        "hdr_cells[1].text = 'message_time'\n",
        "hdr_cells[2].text = 'message_content'\n",
        "linkedin_data = [\n",
        "    ('Alo Olatokunboh Akin', '12:12 PM', 'Wishing you a very happy birthday...'),\n",
        "    ('Ram Tippireddy', '12:00 PM', 'Wishing you a very happy birthday!'),\n",
        "    ('Rediet Dege', '11:27 AM', 'Wishing you a very happy birthday!'),\n",
        "    ('Tikaw Hagos', '11:16 AM', 'Happy birthday!'),\n",
        "    ('Steve Innovations Kenya', '10:12 AM', 'Wishing you a very happy birthday!'),\n",
        "    ('Bahiru G.Awol', '09:22 AM', 'Wishing you a very happy birthday!'),\n",
        "    ('Lemmi Lemma', '08:49 AM', 'Wishing you a very happy birthday!'),\n",
        "    ('Mark Engstar', '08:41 AM', 'Happy Birthday!'),\n",
        "    ('Alapati Sai Srikanth', '07:53 AM', 'Many happy returns of the day Asfaw...'),\n",
        "    ('Chuku Una', '06:44 AM', 'Happy Birthday Asfaw! May God bless yo...'),\n",
        "    ('Dattaram Choudhari', '05:45 AM', 'Wishing you a very happy birthday!'),\n",
        "    ('Ajay Pandit', '05:45 AM', 'Happy birthday')\n",
        "]\n",
        "for sender_name, message_time, message_content in linkedin_data:\n",
        "    row_cells = linkedin_table.add_row().cells\n",
        "    row_cells[0].text = sender_name\n",
        "    row_cells[1].text = message_time\n",
        "    row_cells[2].text = message_content\n",
        "\n",
        "# Step 14: Add subsection for Gratitude Query\n",
        "doc.add_heading('B. Gratitude Query', level=3)\n",
        "doc.add_paragraph(\n",
        "    \"To generate a summary of received birthday\n",
        "::contentReference[oaicite:0]{index=0}\n",
        "\n"
      ],
      "metadata": {
        "id": "jJhaSuTtvS10",
        "outputId": "8952a2ee-51aa-4ee9-f328-3322a4a07175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "id": "jJhaSuTtvS10",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 137) (<ipython-input-2-c09d4a5310dc>, line 137)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c09d4a5310dc>\"\u001b[0;36m, line \u001b[0;32m137\u001b[0m\n\u001b[0;31m    \"To generate a summary of received birthday\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 137)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b644de",
      "metadata": {
        "id": "16b644de"
      },
      "outputs": [],
      "source": [
        "#pip install graphviz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L3ngPwjttj-O",
      "metadata": {
        "id": "L3ngPwjttj-O"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FjJ849dcFBa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "FjJ849dcFBa2",
        "outputId": "9b7f6075-c41a-4053-aeeb-fa11cc42fea9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\'#@title\\n# Libraries for data manipulation and visualization\\nfrom google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''''#@title\n",
        "# Libraries for data manipulation and visualization\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))'''\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TbA2TboVz_25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbA2TboVz_25",
        "outputId": "3c2b6d95-eec9-452a-bd3a-c216e16d6596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Start by connecting gdrive into the google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lfJ8Ujw8y-UN",
      "metadata": {
        "id": "lfJ8Ujw8y-UN"
      },
      "outputs": [],
      "source": [
        "#Start by connecting gdrive into the google colab\n",
        "\n",
        "import os\n",
        "os.chdir (\"/content/gdrive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ObTAXoWg0Lns",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObTAXoWg0Lns",
        "outputId": "a09e2898-63a9-46dc-a37e-5596ce11ed61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: /content/gdrive/MyDrive/Thesis: No such file or directory\n",
            "total 703853\n",
            "-rw------- 1 root root     63032 Mar 15  2024  003.docx\n",
            "-rw------- 1 root root     55525 Mar 10  2024 '01 ·ä£·àµ·çã·ãç ·åà·ã≥·àô .docx'\n",
            "-rw------- 1 root root     33030 Mar 12  2024 '03 Asfaw G (1).docx'\n",
            "-rw------- 1 root root     33030 Mar 12  2024 '03 Asfaw G.docx'\n",
            "-rw------- 1 root root  10127573 Aug 12  2022  ____10______Final.pdf\n",
            "-rw------- 1 root root   1205760 Sep  1  2019  1_IR_intro.ppt\n",
            "-rw------- 1 root root   1807527 Nov  1  2022  20221101_121050.jpg\n",
            "-rw------- 1 root root   2837780 Dec  4  2022  20221204_120833_mfnr.jpg\n",
            "-rw------- 1 root root   1345536 Sep  1  2019 '2_text operation.ppt'\n",
            "-rw------- 1 root root   1504256 Sep  1  2019  3_termWeighting.ppt\n",
            "-rw------- 1 root root   3445071 Apr 17  2021  4_5976689323028776928.pdf\n",
            "-rw------- 1 root root   1160192 Sep  1  2019 '4_ Indexing.ppt'\n",
            "-rw------- 1 root root   1425920 Sep  1  2019  5_IRModels.ppt\n",
            "-rw------- 1 root root   1172992 Sep  1  2019 '6_Retrieval Evaluation.ppt'\n",
            "-rw------- 1 root root   1036800 Sep  1  2019 '7_Query languages.ppt'\n",
            "-rw------- 1 root root  11608023 Jun 10  2021  Abyssinia-The-Powder-Barrel.pdf\n",
            "-rw------- 1 root root     78772 May 26  2017 'Adi Aleza.jpg'\n",
            "-rw------- 1 root root       171 May  6  2023 ' AfricaNLP2023 Workshop.gdoc'\n",
            "-rw------- 1 root root       127 Jan 12  2023 'An untitled mindmap'\n",
            "drwx------ 2 root root      4096 Sep  2  2022 'application process'\n",
            "-rw------- 1 root root    366569 Jan  9  2024  Asfaw-CV-10-01-2024.pdf\n",
            "-rw------- 1 root root    404576 Feb 20  2024  Asfaw_CV_Feb_2024.pdf\n",
            "-rw------- 1 root root    307848 Jan  5  2024  Asfaw-Gedamu-CV-05-01-2024.pdf\n",
            "-rw------- 1 root root   1048187 Jan  9  2023  Asfaw-Gedamu-cv.pdf\n",
            "-rw------- 1 root root       171 Nov 22 19:11  Asgh.gdoc\n",
            "drwx------ 2 root root      4096 Jan 29  2021  Asme\n",
            "drwx------ 2 root root      4096 Aug  5  2022  Assessments\n",
            "-rw------- 1 root root       171 Nov  9  2021  audit.gdoc\n",
            "drwx------ 2 root root      4096 Jan 16  2023 'Basic web services'\n",
            "-rw------- 1 root root  17522992 Sep 18  2021  best_BiLSTM_checkpoint.hdf5\n",
            "-rw------- 1 root root  16378880 Sep 22  2021  best_CNN-BiLSTM_checkpoint.hdf5\n",
            "-rw------- 1 root root  16056864 Sep 22  2021  best_CNN_checkpoint.hdf5\n",
            "-rw------- 1 root root   1083468 May  6  2014  Bewketu_Seyoum_God_and_Ethiopian_Civilization.pdf\n",
            "-rw------- 1 root root     57940 Sep 18  2021  BiLSTM_model_plot.png\n",
            "drwx------ 2 root root      4096 Sep  4  2022  Bjournalism\n",
            "drwx------ 2 root root      4096 Sep  4  2022  Blog\n",
            "-rw------- 1 root root 479546957 Oct 21  2020  Blog.rar\n",
            "drwx------ 2 root root      4096 Aug 28  2020  Books\n",
            "drwx------ 2 root root      4096 May  2  2020  Classroom\n",
            "-rw------- 1 root root    103316 Sep 22  2021  CNN-BiLSTM_model_plot.png\n",
            "-rw------- 1 root root  16055864 Sep  8  2021  cnn_checkpoint.hdf5\n",
            "-rw------- 1 root root     79845 Sep 22  2021  CNN_model_plot.png\n",
            "drwx------ 2 root root      4096 Jan 16  2023 'Co-building information Security culture'\n",
            "drwx------ 2 root root      4096 Aug  4  2020  code\n",
            "drwx------ 2 root root      4096 Apr 12  2023  CoinbaseWalletBackups\n",
            "drwx------ 2 root root      4096 Sep  6  2021 'Colab Notebooks'\n",
            "drwx------ 2 root root      4096 Sep  4  2021  ColabNotebooks\n",
            "-rw------- 1 root root   1516732 May  2  2014 'Communication Theories D. A..pptx'\n",
            "drwx------ 2 root root      4096 Mar 15  2022  Conferences\n",
            "-rw------- 1 root root       171 Aug  5  2022 'Contact Information (1).gform'\n",
            "-rw------- 1 root root       171 Aug  5  2022 'Contact Information.gform'\n",
            "-rw------- 1 root root     89798 Dec 23  2017  Contacts.vcf\n",
            "-rw------- 1 root root       171 Mar 10  2021 'Copy of verification_task_mokshe.gsheet'\n",
            "-r-------- 1 root root     96236 Sep 17  2021 'COURSE CURRICULUM - Advanced Data Analytics using Python and Python Automation Course (40 Hours).pdf'\n",
            "-r-------- 1 root root  56423124 Nov 14 04:15 'Cracking the Coding Interview.pdf'\n",
            "drwx------ 2 root root      4096 May 19  2023  credit-card-fraud-detection\n",
            "drwx------ 2 root root      4096 Jan 16  2023 'Cyber Security'\n",
            "lrw------- 1 root root         0 Aug  3 16:17 'Daniel Kibret  s New book.pdf' -> '/content/gdrive/ '\n",
            "drwx------ 2 root root      4096 Oct 19  2020  data\n",
            "-rw------- 1 root root       171 May 20  2023 'Deep Learning Networks.gslides'\n",
            "drwx------ 2 root root      4096 Jun 23  2022  Degrees\n",
            "-rw------- 1 root root     63756 May 26  2017 'Della Edaga BiEray.jpg'\n",
            "-rw------- 1 root root     81857 May 26  2017 'Della Edaga Kedam.jpg'\n",
            "-rw------- 1 root root     86735 May 26  2017 'Della Ketema.jpg'\n",
            "drwx------ 2 root root      4096 Jan 16  2023  Devops\n",
            "-rw------- 1 root root       171 Mar 31  2021  Dialects_Ti.gsheet\n",
            "-rw------- 1 root root    101090 May 26  2017  Durgimza.jpg\n",
            "-rw------- 1 root root       171 Jul 18  2023 'educational links.gdoc'\n",
            "drwx------ 2 root root      4096 Jun 25  2022  Epic\n",
            "-rw------- 1 root root    341504 Dec 30  2017  eprdf-statement-123017.pdf\n",
            "-rw------- 1 root root    446169 Jun 21  2020  FCG_Asfaw_Gedamu.pdf\n",
            "drwx------ 2 root root      4096 Jan 16  2023 'Final Version ITIO'\n",
            "-rw------- 1 root root       171 May 26  2023 'give me 10 funniest and most entertaining facts about telecommunications and explain them in a fascinating way that goes viral on social media. use iso standard units to describe distance and weight..gdoc'\n",
            "-r-------- 1 root root       171 Mar 10  2023 'Harvard CS197: AI Research Experiences ‚Äì¬†The Course Book.gdoc'\n",
            "drwx------ 2 root root      4096 Sep 23  2021  helloworld\n",
            "-rw------- 1 root root       171 Jun 24  2023 'How do you relate the King Midas touch with Technological singularity?  .gdoc'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Please reason out professionally,. .gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Pl~ionally by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications..gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Pl~lly by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications. (1).gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Pl~lly by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications. (2).gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Pl~lly by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications. (3).gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from Oracle to non-Oracle database, which DB would you recommend? PostgreSQL, MySQL or MS Sql Server? Pl~lly by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications. (4).gsheet'\n",
            "-rw------- 1 root root       171 Jul 21  2023 'if we need to move from relational to non-relational databases, which DB would you recommend? PostgreSQL, MySQL or MS Sql S~ionally by comparing and contrasting the databases in terms of learning curve, budge, technical expertise and applications..gsheet'\n",
            "-rw------- 1 root root   2872826 Jan 10  2022  IMG_20220110_190324.jpg\n",
            "drwx------ 2 root root      4096 Sep  4  2022 'Information_science - Copy'\n",
            "drwx------ 2 root root      4096 Mar 17  2022  IS_Projects\n",
            "drwx------ 2 root root      4096 Aug 12  2022  Java\n",
            "-rw------- 1 root root     55540 May 26  2017 'Keren Ferashi.jpg'\n",
            "-rw------- 1 root root       100 Sep 19 07:18 'Linux System Administration'\n",
            "-r-------- 1 root root       171 Dec 28  2020 'List of tools for MLOps_v1_April 2020.gsheet'\n",
            "-rw------- 1 root root     21495 Dec 13  2022 'Machine Learning(ML)'\n",
            "-rw------- 1 root root  27535475 Feb 15  2019  Major_Sources.rar\n",
            "-rw------- 1 root root     54003 May 26  2017 'Mariam Della.jpg'\n",
            "drwx------ 2 root root      4096 Jun 18  2018  Mavids\n",
            "-rw------- 1 root root    206486 Jun 21  2020 'Maximum Likelihood Estimation.pdf'\n",
            "-rw------- 1 root root   2824621 Nov  3  2021 'McNurlin, Sprague, Bui-IS Management (2014).pdf'\n",
            "-rw------- 1 root root    178179 May 26  2017 'Meida Mesgi to Maiqiltsim.jpg'\n",
            "drwx------ 2 root root      4096 Aug 21  2022  Meles\n",
            "drwx------ 2 root root      4096 Jun  9  2021  merged_combined\n",
            "drwx------ 2 root root      4096 May 19  2021  merged_sources\n",
            "-rw------- 1 root root     54735 Apr 20  2017  messages.am\n",
            "drwx------ 2 root root      4096 Sep 16 03:24  meta-2024-Sep-15-21-34-13\n",
            "drwx------ 2 root root      4096 Dec  8  2022  MindMap\n",
            "drwx------ 2 root root      4096 Sep 23  2021  my_dir\n",
            "drwx------ 2 root root      4096 Jun 28  2024  news_snippets\n",
            "-rw------- 1 root root    269366 Jun 21  2020 'N-Gram and Maximum Likelihood Estimation Asfaw Gedamu.pdf'\n",
            "-rw------- 1 root root       171 Mar 31  2021  North_vs_South_Tigrinya_updated.gsheet\n",
            "drwx------ 2 root root      4096 Aug 30  2021  Notes\n",
            "-rw------- 1 root root       171 Jan  6  2017 'On Feminism & PR.ppt.gslides'\n",
            "-rw------- 1 root root    485923 Jan 17  2018  open-letter-to-DrDebretsion-tplf-chairman.pdf\n",
            "-rw------- 1 root root     25089 Dec  8  2018  Paper_Summary_Assignment_Asfaw_Gedamu.docx\n",
            "-rw------- 1 root root       171 Aug  5  2022 'Party Invite.gform'\n",
            "-rw------- 1 root root  33344505 Oct 21  2020  personal_Docs.zip\n",
            "-rw------- 1 root root     93386 Jan 12  2024  photo_2024-01-12_17-34-34.jpg\n",
            "-rw------- 1 root root       171 Jan 29  2024 'Please prepare a summarized table that shows the 50 biggest social media platforms, year of founding, and the year profitab~ and In August 2004, LinkedIn reached 1 million users.¬†In March 2006, LinkedIn achieved its first month of profitability. .gsheet'\n",
            "-rw------- 1 root root       171 Jan 10  2024 'Please provide and Overview of product development (TTM phases) and RASCI (1).gsheet'\n",
            "-rw------- 1 root root       171 Jan 10  2024 'Please provide and Overview of product development (TTM phases) and RASCI.gsheet'\n",
            "-rw------- 1 root root       171 Jan 17  2024 'Please provide an Overview of product development (TTM phases) and RASCI. Include the typies of product testing in each phase. '$'\\n''.gsheet'\n",
            "-rw------- 1 root root       171 Jan 17  2024 'Please provide an Overview of product development (TTM phases: Ideation and concept, planning and requirements, design and ~ity assurance, launch and rollout, maintenance and growth) and RASCI. Include the typies of product testing in each phase. .gsheet'\n",
            "-rw------- 1 root root      2352 Dec 27  2023 'Product testing '\n",
            "-rw------- 1 root root     17465 Jan 11  2024 'Product Testing'\n",
            "-rw------- 1 root root     21375 Jan 11  2024 'Product Testing.pdf'\n",
            "-rw------- 1 root root      5491 Dec 28  2023 'Product Testing updated'\n",
            "drwx------ 2 root root      4096 Jan 29  2024  proskils\n",
            "-rw------- 1 root root     65103 May 26  2017 'Qebtsiya Monastry.jpg'\n",
            "-rw------- 1 root root       171 Oct 18  2020  Resume.gdoc\n",
            "-rw------- 1 root root       171 Sep 29  2022 'Scholarship links.gdoc'\n",
            "-rw------- 1 root root       100 Sep 19 13:35 'Software Development Frameworks'\n",
            "-rw------- 1 root root     96063 Jul 26  2023 'SQL Server 2019 Diagnostic Information Queries.sql'\n",
            "-rw------- 1 root root       171 Oct 16  2009  status.gsheet\n",
            "-rw------- 1 root root       171 Oct 18  2020 'Summary - Knowledge Science -Modeling the Knowledge Creation Process.gdoc'\n",
            "drwx------ 2 root root      4096 Jan 23  2021  Takeout\n",
            "-rw------- 1 root root     38429 Apr 26  2021 'task_01 Edited.docx'\n",
            "drwx------ 2 root root      4096 May 19  2023  telecom-customer-churn\n",
            "-rw------- 1 root root     40527 Sep 13 12:05 'TExA_IS Offers section_Attendance follow up May 15 - June 14 2024.xlsx'\n",
            "lrw------- 1 root root         0 Sep 19  2021  Thesis -> /content/gdrive/.shortcut-targets-by-id/15SwmMal_md7FiV8-9Sgmk-HzXNJxQS-x/Thesis\n",
            "-rw------- 1 root root     14227 Sep 28  2021 'Thesis Defense Schedule.xlsx'\n",
            "-rw------- 1 root root       159 Nov  2 23:36 'Tigray and Afar.gmap'\n",
            "drwx------ 2 root root      4096 Apr 19  2023 'Tigrinya Dialect Identification'\n",
            "-rw------- 1 root root       171 Aug  5  2022 'T-Shirt Sign Up.gform'\n",
            "-rw------- 1 root root       171 Jan 21  2023 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root       171 Aug 30  2021 'Untitled document (2).gdoc'\n",
            "-rw------- 1 root root       171 Apr 17  2023 'Untitled document.gdoc'\n",
            "-rw------- 1 root root       171 Jan 12  2022 'Untitled drawing.gdraw'\n",
            "-rw------- 1 root root       171 Nov 26 11:40 'Untitled presentation.gslides'\n",
            "-rw------- 1 root root       184 Aug  5  2021 'Untitled project.gscript'\n",
            "-rw------- 1 root root       171 Nov 17  2010 'vc traffic & revenue per week.gsheet'\n",
            "-rw------- 1 root root    823213 Dec 13  2020  verification_task_forms_checked.xlsx\n",
            "-rw------- 1 root root   2841708 Dec 22  2020  verification_task_mokshe_sofar.xlsx\n",
            "-rw------- 1 root root       171 May 30  2023 'What are the best online surveying tools for sales and marketing professionals? Online surveys can be conducted using survey monkey, Google Docs and others. Give me five top online surveying tools and evaluate their strengths and weaknesses..gdoc'\n",
            "-rw------- 1 root root       171 Mar  3  2024 'What are the core differences between SQL and No-....gsheet'\n",
            "-rw------- 1 root root       171 Jan 31  2024 'What are the main differences between Oracle DB partitioning and PostgreSQL DB partitioning? Please provide your response in tables and graphs..gsheet'\n",
            "-rw------- 1 root root       171 Jun  7  2023 'What are the six levels of automation that CSPs envision to achieve?.gdoc'\n",
            "-rw------- 1 root root       171 Jan 18  2023 '·ä£·ä®·â£·â•·à´ ·â•·ãì·àç ·å•·àù·âÄ·âµ.gdoc'\n",
            "-rw------- 1 root root    314327 May 27  2016 '·ã®·ãù·åç·åÖ·â± ·à≠·ä•·àµ·ç°-·çà·àà·åà ·å•·â†·â•.docx'\n",
            "-r-------- 1 root root   1046231 Nov 16  2022  ·åà·äê·â≤·äì.pdf\n"
          ]
        }
      ],
      "source": [
        "!ls -l /content/gdrive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oVTwScUV3UjC",
      "metadata": {
        "id": "oVTwScUV3UjC"
      },
      "outputs": [],
      "source": [
        "!cd ColabNotebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EEk8reZp47LB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEk8reZp47LB",
        "outputId": "aad85d2f-057c-4c41-ef5d-825cf88bbf79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'all_source111 (1).gsheet'   all_source3.tsv\n",
            "'all_source111 (2).gsheet'   DL-char-ngrams.ipynb\n",
            " all_source111.gsheet\t    'Multi-Class Text Classification with LSTM TDI  .ipynb'\n",
            " all_source111.tsv\t    'Text Classification with LSTM TDI .ipynb'\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "!ls ColabNotebooks\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6GHpBSoVGKnc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GHpBSoVGKnc",
        "outputId": "d5bf4d63-0722-47f5-a482-24b292e3a109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad27846",
      "metadata": {
        "id": "9ad27846"
      },
      "outputs": [],
      "source": [
        "#Text Preprocessing step\n",
        "#Remove alphanumeric characters, punctuation marks and symbols\n",
        "\n",
        "BLOCK_CHAR = \"\"\"'()[]\":·ç£·ç°·ç°·ç°‚Äú‚Äù·ç¢?::·ç•·ç§]+\\*_-‚Äò‚Äô!\"\"\" + 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "BLOCK_CHAR = ''.join(BLOCK_CHAR.split())\n",
        "\n",
        "def clean_text(raw_text):\n",
        "    #raw_text = re.sub(r\"()[\"\":·ç£ ·ç°·ç°''·ç°‚Äú ‚Äù ·ç¢?::·ç•·ç§]+\\ *\", \" \", raw_text)\n",
        "    for c in BLOCK_CHAR:\n",
        "        if c not in raw_text:\n",
        "            continue\n",
        "        raw_text = raw_text.replace(c, '')\n",
        "    return raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e858f4",
      "metadata": {
        "id": "f8e858f4"
      },
      "outputs": [],
      "source": [
        "def load_data(fin):\n",
        "    '''accepts fin a string representing file name\n",
        "    returns list of lines in a file'''\n",
        "    X = []\n",
        "    y = []\n",
        "    with open(fin, encoding=\"utf8\") as f:\n",
        "        labels = next(f).rstrip('\\n').split('\\t')\n",
        "        for line in f:\n",
        "            parts = line.rstrip('\\n').split('\\t')\n",
        "            if len(set(parts)) != 3:\n",
        "                continue\n",
        "            for part, label in zip(parts, labels):\n",
        "                part = clean_text(part)\n",
        "                if part.strip() == '':\n",
        "                    continue\n",
        "                X.append(part)\n",
        "                y.append(label)\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dZ2IeGuZkeMm",
      "metadata": {
        "id": "dZ2IeGuZkeMm"
      },
      "outputs": [],
      "source": [
        "def load_data(fin):\n",
        "  \"\"\"\n",
        "  Accepts a string representing a filename and returns a list of lines and labels.\n",
        "\n",
        "  Args:\n",
        "      fin: The filename of the data file.\n",
        "\n",
        "  Returns:\n",
        "      A tuple containing two lists:\n",
        "          - X: A list of data points (text).\n",
        "          - y: A list of corresponding labels.\n",
        "  \"\"\"\n",
        "  X = []\n",
        "  y = []\n",
        "  with open(fin, 'r', encoding='utf-8') as f:\n",
        "    try:\n",
        "      # Read labels line using UTF-8 encoding\n",
        "      labels = next(f).rstrip('\\n').split('\\t')\n",
        "      for line in f:\n",
        "        parts = line.rstrip('\\n').split('\\t')\n",
        "        if len(set(parts)) != 3:\n",
        "          continue\n",
        "        for part, label in zip(parts, labels):\n",
        "          part = clean_text(part)\n",
        "          if part.strip() == '':\n",
        "            continue\n",
        "          X.append(part)\n",
        "          y.append(label)\n",
        "    except UnicodeDecodeError:  # Handle potential encoding errors\n",
        "      print(f\"Error: Encountered encoding issue with file {fin}.\")\n",
        "      print(\"Trying alternative encodings...\")\n",
        "      encodings = ['latin-1', 'cp1252']  # List of potential encodings to try\n",
        "      for encoding in encodings:\n",
        "        try:\n",
        "          # Read labels line with the current encoding\n",
        "          with open(fin, 'r', encoding=encoding) as f:\n",
        "            labels = next(f).rstrip('\\n').split('\\t')\n",
        "            for line in f:\n",
        "              parts = line.rstrip('\\n').split('\\t')\n",
        "              if len(set(parts)) != 3:\n",
        "                continue\n",
        "              for part, label in zip(parts, labels):\n",
        "                part = clean_text(part)\n",
        "                if part.strip() == '':\n",
        "                  continue\n",
        "                X.append(part)\n",
        "                y.append(label)\n",
        "          # If successful, break out of the loop\n",
        "          print(f\"Successfully loaded data using encoding: {encoding}\")\n",
        "          break\n",
        "        except UnicodeDecodeError:\n",
        "          # If decoding fails with the current encoding, continue to the next one\n",
        "          print(f\"Encoding {encoding} failed. Trying next...\")\n",
        "      else:\n",
        "        # If all encodings fail, raise an informative error\n",
        "        print(\"Failed to decode data using any of the provided encodings.\")\n",
        "        raise UnicodeDecodeError(\"Encountered encoding issue with file and couldn't find a suitable encoding.\")\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b117ddf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b117ddf",
        "outputId": "45f5d411-08ca-4603-b77b-2cfc31f4cbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Encountered encoding issue with file /content/gdrive/MyDrive/ColabNotebooks/all_source3.tsv.\n",
            "Trying alternative encodings...\n",
            "Successfully loaded data using encoding: latin-1\n"
          ]
        }
      ],
      "source": [
        "X,y = load_data('/content/gdrive/MyDrive/ColabNotebooks/all_source3.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612c01f6",
      "metadata": {
        "id": "612c01f6"
      },
      "outputs": [],
      "source": [
        "def gen_ngrams(s, ns=(1,2,3)):\n",
        "    '''takes s string and ns tuple as arguments\n",
        "    generates ngram strings'''\n",
        "    for n in ns:\n",
        "        for ngram in ngrams(s,n):\n",
        "            ngram = ''.join(ngram)\n",
        "            yield ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2876734",
      "metadata": {
        "id": "a2876734"
      },
      "outputs": [],
      "source": [
        "def ngram_freq(sents, ns=(1,2,3)):\n",
        "    ngram_tokens = defaultdict(int)\n",
        "    for s in sents:\n",
        "        for ngram in gen_ngrams(s, ns):\n",
        "            ngram_tokens[ngram] += 1\n",
        "    return ngram_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb226df1",
      "metadata": {
        "id": "fb226df1"
      },
      "outputs": [],
      "source": [
        "# generating ngrams with values 1, 2 and 3\n",
        "ngram_tokens = ngram_freq(X, ns=(1,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d61090",
      "metadata": {
        "id": "70d61090"
      },
      "outputs": [],
      "source": [
        "# sorts ngrams by frequency from most frequent to least frequent\n",
        "top_ngrams_freq = sorted(ngram_tokens.items(), key=lambda x:x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18edfcd4",
      "metadata": {
        "id": "18edfcd4"
      },
      "outputs": [],
      "source": [
        "word_list =  [oov_tok] + [i[0] for i in top_ngrams_freq[:max_features]]\n",
        "word_index = dict([(j,i) for (i,j) in enumerate(word_list, start=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35338a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35338a6",
        "outputId": "ab2a9978-b248-4a2d-cef0-3e56f549b3f2",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " '\\x9c': 2,\n",
              " '¬æ': 3,\n",
              " '9': 4,\n",
              " '=': 5,\n",
              " '\\x8e': 6,\n",
              " '\\x95': 7,\n",
              " '2': 8,\n",
              " '√â': 9,\n",
              " '√ç': 10}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(list(word_index.items())[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0328d6d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0328d6d7",
        "outputId": "fb05fdfd-5b91-441d-8b1c-b5ea007a2f0f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{√Ç√µ√ì\\x84¬´√ª¬´\\x97\\x0c¬°√Ö\\x08\\x85=√°\\x87√ú√Ö¬∫\\xa0√£\\x02\\x1f√Ä¬ß'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe2b5d1",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "abe2b5d1",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Note: the ngram sequence (ns) we use for feature generation must match the one used to build the dictionary\n",
        "#[i for i in gen_ngrams(X[0], ns=(1,))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e186da7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e186da7b",
        "outputId": "6f7cf39c-077d-4a24-cc62-95bd4aa93790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['·ä•', '·â≤', ' ', '·äì', '·ã≠', '·âµ', '·åç', '·à´', '·ã≠', ' ', '·â¥', '·àå', '·â™', '·ã•', '·äï', ' ', '·åã', '·ãú', '·å†', '·äõ', ' ', '·ãÆ', '·ãç', '·àÉ', '·äï', '·àµ', ' ', '·ãù', '·â†', '·àÉ', '·àç', ' ', '·åç', '·äï', ' ', '·åã', '·ãú', '·å†', '·äõ', '·ã∂', ' ', '·ãà', '·ã≠', '·àµ', ' ', '·ãà', '·ä™', '·àç', ' ', '·àÖ', '·ãà', '·àì', '·âµ', ' ', '·ã≠', '·åç', '·à≠', '·àù', 1, 1, 179, 1, 1, 1, 1, 1, 1, 179, 1, 1, 1, 1, 1, 179, 1, 1, 1, 1, 179, 1, 1, 1, 1, 1, 179, 1, 1, 1, 1, 179, 1, 1, 179, 1, 1, 1, 1, 1, 179, 1, 1, 1, 179, 1, 1, 1, 179, 1, 1, 1, 1, 179, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Sample text to confirm if the codes above are working\n",
        "\n",
        "a = '·ä•·â≤ ·äì·ã≠·âµ·åç·à´·ã≠ ·â¥·àå·â™·ã•·äï ·åã·ãú·å†·äõ ·ãÆ·ãç·àÉ·äï·àµ ·ãù·â†·àÉ·àç ·åç·äï ·åã·ãú·å†·äõ·ã∂ ·ãà·ã≠·àµ ·ãà·ä™·àç ·àÖ·ãà·àì·âµ ·ã≠·åç·à≠·àù'\n",
        "t = [i for i in gen_ngrams(a, ns=(1,))]\n",
        "idx = [word_index.get(tok, 1) for tok in t]\n",
        "#print(t)\n",
        "print(t + idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c7e86d",
      "metadata": {
        "id": "93c7e86d"
      },
      "outputs": [],
      "source": [
        "def tokenizer(X, ns=(1,2)):\n",
        "    \"\"\"using list comprehension\n",
        "    X_tok = [i for i in gen_ngrams(x, ns=(1,2,3)) for x in X]\n",
        "    \"\"\"\n",
        "    tokenized = []\n",
        "    for x in X:\n",
        "        toks = [tok for tok in gen_ngrams(x, ns)]\n",
        "        idx = [word_index.get(tok, 1) for tok in toks]\n",
        "        tokenized.append(idx)\n",
        "        if max(idx) > 20000 + 1:\n",
        "            print(x)\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abf6bed",
      "metadata": {
        "id": "9abf6bed"
      },
      "outputs": [],
      "source": [
        "X_tok = tokenizer(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aae7856",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aae7856",
        "outputId": "0bb84a64-6cb4-4629-aa4e-8c876a36ea9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[50, 59, 34, 1, 1]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tok[1][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2ef2db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "be2ef2db",
        "outputId": "39d5f071-16c2-48df-f89b-4541cf7483ef"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'·â•'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-36d19ce4781b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'·â•'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '·â•'"
          ]
        }
      ],
      "source": [
        "word_index['·â•']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba5afae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ba5afae",
        "outputId": "481eb8da-bc5b-4ea2-a980-a04efd087fe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1435"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# maximum length of tokens in our dataset\n",
        "max([len(X_tok[i]) for i in range(len(X_tok))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23baf32e",
      "metadata": {
        "id": "23baf32e"
      },
      "outputs": [],
      "source": [
        "# Which sentences is this?\n",
        "# TODO: Should we sort features?\n",
        "for idx, i in enumerate(range(len(X_tok))):\n",
        "    if len(X_tok[i]) == 503:\n",
        "        print(idx)\n",
        "        print(X[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c621b890",
      "metadata": {
        "id": "c621b890"
      },
      "outputs": [],
      "source": [
        "# Pads a single character\n",
        "\n",
        "def pad_seq(l, max_length):\n",
        "    if len(l) == max_length:\n",
        "        return l\n",
        "    elif len(l) < max_length:\n",
        "        return l + [1]*(max_length - len(l))\n",
        "    else:\n",
        "        return l[:max_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3901c082",
      "metadata": {
        "id": "3901c082"
      },
      "outputs": [],
      "source": [
        "# Pads all input sequences\n",
        "\n",
        "def pad_seqs(X, max_length):\n",
        "    res = []\n",
        "    for x in X:\n",
        "        l = np.array(pad_seq(x, max_length))\n",
        "        res.append(l)\n",
        "    return np.array(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf3033b",
      "metadata": {
        "id": "ecf3033b"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "#X_tok_padded = pad_sequences(X_tok, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "X_tok_padded = pad_seqs(X_tok, max_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd4cff1",
      "metadata": {
        "id": "2bd4cff1"
      },
      "outputs": [],
      "source": [
        "#our labels are in Z, L, D but we want a three dimensional vector corresponding to each class\n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "y_ = lb.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1db0cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1db0cc2",
        "outputId": "55b97f11-8e3c-4b21-877b-293e69f79e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['PK\\x03\\x04\\x14\\x00\\x08\\x08\\x08\\x00i\\x1d\\x9fY\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00xl/tables/table1.xmlm\\x90√çN√É0\\x10\\x84\\x9f\\x80w¬∞√∂√û8i\\x11\\xa0¬™I\\x85\\x8a*!U\\x1ch¬πp¬©L¬≤i,√π\\'√≤:-y{\\x1c\\x1c\\xa0\\x15=√Æ|;\\x9a√ë,\\x96\\x9fZ¬±#:\\x92√ñ√§\\x90%)04¬•\\xad¬§9√§√∞¬∂[O\\x1e\\x80\\x91\\x17¬¶\\x12√ä\\x1a√å¬°G\\x82eq¬≥√∞√¢C!\\x0bfC94√û¬∑s√é¬©lP\\x0bJl\\x8b&\\x90√ö:-|8√ù\\x81S√´PT√î z\\xad√∏4M√Ø¬∏\\x16√í\\x00sX√ß√∞\\x98√çW¬∑iv\\x0f¬¨\\x92√î*√ë¬ø\\x08\\x1d¬≤vC√Ü>\\x03f.OY\\x85¬¶P√Ñ\\x0e+¬´:m\\x88\\x95¬∂3>\\x87√ô¬•>Z√ü\\x7fL√º\\x1a√ùD:¬ΩN\\x9f\"\\x9d', 'PK\\x03\\x04\\x14\\x00\\x08\\x08\\x08\\x00i\\x1d\\x9fY\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00xl/tables/table1.xmlm\\x90√çN√É0\\x10\\x84\\x9f\\x80w¬∞√∂√û8i\\x11\\xa0¬™I\\x85\\x8a*!U\\x1ch¬πp¬©L¬≤i,√π\\'√≤:-y{\\x1c\\x1c\\xa0\\x15=√Æ|;\\x9a√ë,\\x96\\x9fZ¬±#:\\x92√ñ√§\\x90%)04¬•\\xad¬§9√§√∞¬∂[O\\x1e\\x80\\x91\\x17¬¶\\x12√ä\\x1a√å¬°G\\x82eq¬≥√∞√¢C!\\x0bfC94√û¬∑s√é¬©lP\\x0bJl\\x8b&\\x90√ö:-|8√ù\\x81S√´PT√î z\\xad√∏4M√Ø¬∏\\x16√í\\x00sX√ß√∞\\x98√çW¬∑iv\\x0f¬¨\\x92√î*√ë¬ø\\x08\\x1d¬≤vC√Ü>\\x03f.OY\\x85¬¶P√Ñ\\x0e+¬´:m\\x88\\x95¬∂3>\\x87√ô¬•>Z√ü\\x7fL√º\\x1a√ùD:¬ΩN\\x9f\"\\x9d', 'PK\\x03\\x04\\x14\\x00\\x08\\x08\\x08\\x00i\\x1d\\x9fY\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00xl/tables/table1.xmlm\\x90√çN√É0\\x10\\x84\\x9f\\x80w¬∞√∂√û8i\\x11\\xa0¬™I\\x85\\x8a*!U\\x1ch¬πp¬©L¬≤i,√π\\'√≤:-y{\\x1c\\x1c\\xa0\\x15=√Æ|;\\x9a√ë,\\x96\\x9fZ¬±#:\\x92√ñ√§\\x90%)04¬•\\xad¬§9√§√∞¬∂[O\\x1e\\x80\\x91\\x17¬¶\\x12√ä\\x1a√å¬°G\\x82eq¬≥√∞√¢C!\\x0bfC94√û¬∑s√é¬©lP\\x0bJl\\x8b&\\x90√ö:-|8√ù\\x81S√´PT√î z\\xad√∏4M√Ø¬∏\\x16√í\\x00sX√ß√∞\\x98√çW¬∑iv\\x0f¬¨\\x92√î*√ë¬ø\\x08\\x1d¬≤vC√Ü>\\x03f.OY\\x85¬¶P√Ñ\\x0e+¬´:m\\x88\\x95¬∂3>\\x87√ô¬•>Z√ü\\x7fL√º\\x1a√ùD:¬ΩN\\x9f\"\\x9d', 'PK\\x03\\x04\\x14\\x00\\x08\\x08\\x08\\x00i\\x1d\\x9fY\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00xl/tables/table1.xmlm\\x90√çN√É0\\x10\\x84\\x9f\\x80w¬∞√∂√û8i\\x11\\xa0¬™I\\x85\\x8a*!U\\x1ch¬πp¬©L¬≤i,√π\\'√≤:-y{\\x1c\\x1c\\xa0\\x15=√Æ|;\\x9a√ë,\\x96\\x9fZ¬±#:\\x92√ñ√§\\x90%)04¬•\\xad¬§9√§√∞¬∂[O\\x1e\\x80\\x91\\x17¬¶\\x12√ä\\x1a√å¬°G\\x82eq¬≥√∞√¢C!\\x0bfC94√û¬∑s√é¬©lP\\x0bJl\\x8b&\\x90√ö:-|8√ù\\x81S√´PT√î z\\xad√∏4M√Ø¬∏\\x16√í\\x00sX√ß√∞\\x98√çW¬∑iv\\x0f¬¨\\x92√î*√ë¬ø\\x08\\x1d¬≤vC√Ü>\\x03f.OY\\x85¬¶P√Ñ\\x0e+¬´:m\\x88\\x95¬∂3>\\x87√ô¬•>Z√ü\\x7fL√º\\x1a√ùD:¬ΩN\\x9f\"\\x9d', 'PK\\x03\\x04\\x14\\x00\\x08\\x08\\x08\\x00i\\x1d\\x9fY\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00xl/tables/table1.xmlm\\x90√çN√É0\\x10\\x84\\x9f\\x80w¬∞√∂√û8i\\x11\\xa0¬™I\\x85\\x8a*!U\\x1ch¬πp¬©L¬≤i,√π\\'√≤:-y{\\x1c\\x1c\\xa0\\x15=√Æ|;\\x9a√ë,\\x96\\x9fZ¬±#:\\x92√ñ√§\\x90%)04¬•\\xad¬§9√§√∞¬∂[O\\x1e\\x80\\x91\\x17¬¶\\x12√ä\\x1a√å¬°G\\x82eq¬≥√∞√¢C!\\x0bfC94√û¬∑s√é¬©lP\\x0bJl\\x8b&\\x90√ö:-|8√ù\\x81S√´PT√î z\\xad√∏4M√Ø¬∏\\x16√í\\x00sX√ß√∞\\x98√çW¬∑iv\\x0f¬¨\\x92√î*√ë¬ø\\x08\\x1d¬≤vC√Ü>\\x03f.OY\\x85¬¶P√Ñ\\x0e+¬´:m\\x88\\x95¬∂3>\\x87√ô¬•>Z√ü\\x7fL√º\\x1a√ùD:¬ΩN\\x9f\"\\x9d']\n"
          ]
        }
      ],
      "source": [
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e4ba61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9e4ba61",
        "outputId": "57fd9bcf-b7f2-4a59-90b7-5b4c6c5c1068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "print(y_[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c559864c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c559864c",
        "outputId": "207df085-7f0b-40c7-a27f-0e4ea7485242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203\n",
            "203\n",
            "162 162\n",
            "41 41\n",
            "Train shape: (162, 500)\n",
            "Test shape: (41, 500)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tok_padded, y_, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(X))\n",
        "print(len(y))\n",
        "\n",
        "print(len(X_train), len(y_train))\n",
        "print(len(X_test), len(y_test))\n",
        "\n",
        "print('Train shape:',X_train.shape)\n",
        "print('Test shape:',X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46961eb",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46961eb",
        "outputId": "99d97144-4307-4474-cc2b-1f213c4f7608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer([X[0]])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44c0d87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e44c0d87",
        "outputId": "132f51ac-a8f7-44ce-86f1-7c343ad6e269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([142, 111, 128, 186,  81, 175, 160,  49,  23,  94,  47,  41, 142,\n",
              "       116,  18, 167, 161,  96, 134, 118, 180, 147, 181,  41,  56,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "         1,   1,   1,   1,   1,   1,   1,   1,   1])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0][:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "210fd643",
      "metadata": {
        "id": "210fd643"
      },
      "source": [
        "# BI-LSTM Reference\n",
        "\n",
        "Fran√ßois Chollet.(2020/05/03). Bidirectional LSTM on IMDB. Retrieved 30 August 2021, from: https://keras.io/examples/nlp/bidirectional_lstm_imdb/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4ec482",
      "metadata": {
        "id": "4c4ec482"
      },
      "outputs": [],
      "source": [
        "# create a Bi-LSTM model\n",
        "def BiLSTM_model(drop_out, filter_one, filter_two, last_dense, padding, num_epochs):\n",
        "    model = tf.keras.Sequential([\n",
        "        # Add an Embedding layer expecting input vocab of size 20000,\n",
        "        # and output embedding dimension of size 64 we set at the top\n",
        "        tf.keras.layers.Embedding(max_features+2,embedding_dim,input_shape=(500,)),\n",
        "        #To add Bidirectional layers sequencially, use return_sequences=True\n",
        "\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(filter_one, return_sequences=True)),\n",
        "        #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(filter_one,return_sequences=True)),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "        # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
        "        #tf.keras.layers.Dense(last_dense, activation='relu'), #Check with and without this layer\n",
        "\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(filter_two)),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        # Add a Dense layer with 3 units and softmax activation.\n",
        "        # We have three outputs, softmax converts output layers into a probability distribution.\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    #Drow the BiLSTM Neural Network architecture\n",
        "\n",
        "    #plot_model(model, to_file='./BiLSTM_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    #fit the model\n",
        "    #checkpointer = ModelCheckpoint(filepath='./best_BiLSTM_checkpoint.hdf5',\n",
        "                                   #verbose=1,\n",
        "                                   #save_best_only=True,\n",
        "                                   #save_weights_only=False,\n",
        "                                   #monitor='val_accuracy',\n",
        "                                   #mode='max',\n",
        "                                   #save_freq=\"epoch\")\n",
        "    # Model weights are saved at the end of every epoch, if it's the best seen so far\n",
        "    history = model.fit(X_train, y_train, epochs=num_epochs,validation_data=(X_test, y_test), verbose=2,callbacks=[checkpointer])\n",
        "\n",
        "    # Evaluate the model on the test data (this is for testing time, with the testing dataset)\n",
        "    # Returns the loss value & metrics values for the model in test mode.\n",
        "\n",
        "    print('\\n')\n",
        "    print(\"Evaluate on test data\",'\\n')\n",
        "    results = model.evaluate(X_test, y_test, batch_size=64)\n",
        "    print(\"Test Loss:\",results[0])\n",
        "    print(\"Test Accuracy:\",results[1])\n",
        "\n",
        "    # Generate output predictions for the input samples(probabilities -the output of the last layer) on new data\n",
        "    # (this is for somewhere between training and testing time).\n",
        "    # Use this model to do some feed-forward passes to predict novel inputs.\n",
        "\n",
        "    print('\\n')\n",
        "    #assert np.allclose(model.predict(X_test), loaded_model.predict(X_test))\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"predictions shape:\", predictions.shape)\n",
        "    y_pred = (predictions)\n",
        "\n",
        "    #Creating a confusion matrix,which compares the y_test and y_pred\n",
        "    #Note The support column in classification_report is:\n",
        "    #the number of occurrences of each class in y_test.It shows testset distribution\n",
        "    # Plotting training and validation loss graph\n",
        "\n",
        "    results = pd.DataFrame(\n",
        "    confusion_matrix( y_test.argmax(axis=1), y_pred.argmax(axis=1)),\n",
        "    index=['D', 'L', 'Z'],\n",
        "    columns=['D', 'L', 'Z'])\n",
        "\n",
        "    print('-'*80,'\\n')\n",
        "    print('Confusion Matrix of BiLSTM Model', '\\n')\n",
        "    print(results,'\\n')\n",
        "\n",
        "    print('Classification Report : ','\\n')\n",
        "    target_names = ['D-variety', 'L-variety', 'Z-variety']\n",
        "    print (classification_report(y_test.argmax(axis=1),y_pred.argmax(axis=1),target_names=target_names),'\\n')\n",
        "\n",
        "   # Plotting training and validation loss graph\n",
        "    print(\"Plotting Loss and Accuracy Graphs\",'\\n')\n",
        "    plt.plot(history.history['loss'], label='train loss')\n",
        "    plt.plot(history.history['val_loss'], label='val loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting training and validation Accuracy graph\n",
        "    plt.plot(history.history['accuracy'], label='train acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UdfP3ezXjo5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "UdfP3ezXjo5b",
        "outputId": "f666cd37-9301-4881-f4f2-f895ef42b94a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 64)           1280128   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 500, 128)          66048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 500, 128)          0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1453443 (5.54 MB)\n",
            "Trainable params: 1453443 (5.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'checkpointer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-50cc749b3706>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mBiLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_two\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-b88a6ad1d1c6>\u001b[0m in \u001b[0;36mBiLSTM_model\u001b[0;34m(drop_out, filter_one, filter_two, last_dense, padding, num_epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                    \u001b[0;31m#save_freq=\"epoch\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Model weights are saved at the end of every epoch, if it's the best seen so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Evaluate the model on the test data (this is for testing time, with the testing dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpointer' is not defined"
          ]
        }
      ],
      "source": [
        "max_features = max_features\n",
        "embedding_dim = 64\n",
        "BiLSTM_model(drop_out=0.6,filter_one=64,filter_two=64,last_dense=64,padding='same',num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "415abf1a",
      "metadata": {
        "id": "415abf1a"
      },
      "source": [
        "# CNN  Model Reference\n",
        "\n",
        "Mark Omernick, Francois Chollet. (2019). Text classification from scratch. Retrieved on 30 August 2021, from: https://keras.io/examples/nlp/text_classification_from_scratch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37251a69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "37251a69",
        "outputId": "32e6038c-332b-4547-9e0c-31ac3f4eb514"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.utils.vis_utils'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-9f9145532d8c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create CNN Function to use the keras model in the scikit-learn wrapping class KerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#To use this wrapper we must define a function that creates and returns your Keras sequential model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_two\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# create a CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Create CNN Function to use the keras model in the scikit-learn wrapping class KerasClassifier\n",
        "#To use this wrapper we must define a function that creates and returns your Keras sequential model,\n",
        "from keras.utils.vis_utils import plot_model\n",
        "def cnn_model(drop_out, filter_one, filter_two, last_dense,learning_rate, padding,num_epochs):\n",
        "    # create a CNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        # Add an Embedding layer expecting input vocab of size 20000, and output embedding dimension of size 64 we set at the top\n",
        "        tf.keras.layers.Embedding(max_features+2,embedding_dim,input_shape=(500,)),\n",
        "\n",
        "        # use ReLU in place of tanh function since they are very good alternatives of each other\n",
        "        tf.keras.layers.Conv1D(filters=128, kernel_size=3,padding=padding,activation='relu'),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "        # Conv1D + global max pooling\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=3,padding=padding,activation='relu'),\n",
        "        tf.keras.layers.GlobalMaxPool1D(),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "\n",
        "        # Add a vanilla hidden layer\n",
        "        tf.keras.layers.Dense(last_dense,activation='relu'),\n",
        "\n",
        "        # Add a Dense layer with 3 units since the output should be three(no. Classes)\n",
        "        # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    # Decide a model architecture, this is the number of hidden layers and activation functions, etc.\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    plot_model(model, to_file='./CNN_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    # Train the model for a given number of epochs(this is for training time, with the training dataset).\n",
        "    # Train our model to get all the paramters to the correct value to map our inputs to our outputs.\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath='./best_CNN_checkpoint.hdf5',\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=False,\n",
        "                                   monitor='val_accuracy',\n",
        "                                   mode='max',\n",
        "                                   save_freq=\"epoch\")\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=num_epochs,validation_data=(X_test, y_test), verbose=2,callbacks=[checkpointer])\n",
        "\n",
        "    # Evaluate the model on the test data (this is for testing time, with the testing dataset)\n",
        "    # Returns the loss value & metrics values for the model in test mode.\n",
        "\n",
        "    print('\\n')\n",
        "    print(\"Evaluate on test data\",'\\n')\n",
        "    results = model.evaluate(X_test, y_test, batch_size=64)\n",
        "    print(\"Test Loss:\",results[0])\n",
        "    print(\"Test Accuracy:\",results[1])\n",
        "\n",
        "    # Generate output predictions for the input samples(probabilities -the output of the last layer) on new data\n",
        "    # (this is for somewhere between training and testing time).\n",
        "    # Use this model to do some feed-forward passes to predict novel inputs.\n",
        "\n",
        "    print('\\n')\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"predictions shape:\", predictions.shape)\n",
        "    y_pred = (predictions)\n",
        "\n",
        "    #Creating a confusion matrix,which compares the y_test and y_pred\n",
        "    #Note The support column in classification_report is:\n",
        "    #the number of occurrences of each class in y_test.It shows testset distribution\n",
        "    # Plotting training and validation loss graph\n",
        "\n",
        "    results = pd.DataFrame(\n",
        "    confusion_matrix( y_test.argmax(axis=1), y_pred.argmax(axis=1)),\n",
        "    index=['D', 'L', 'Z'],\n",
        "    columns=['D', 'L', 'Z'])\n",
        "\n",
        "    print('-'*80,'\\n')\n",
        "    print('Confusion Matrix of CNN Model', '\\n')\n",
        "    print(results,'\\n')\n",
        "\n",
        "    print('Classification Report : ','\\n')\n",
        "    target_names = ['D-variety', 'L-variety', 'Z-variety']\n",
        "    print (classification_report(y_test.argmax(axis=1),y_pred.argmax(axis=1),target_names=target_names),'\\n')\n",
        "\n",
        "   # Plotting training and validation loss graph\n",
        "    print(\"Plotting Loss and Accuracy Graphs\",'\\n')\n",
        "    plt.plot(history.history['loss'], label='train loss')\n",
        "    plt.plot(history.history['val_loss'], label='val loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting training and validation Accuracy graph\n",
        "    plt.plot(history.history['accuracy'], label='train acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jgtbwzVMNDJt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "jgtbwzVMNDJt",
        "outputId": "dba22d6a-a4f5-4d17-f488-77385c4f76d5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cnn_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-9bd2ad627019>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_two\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_model' is not defined"
          ]
        }
      ],
      "source": [
        "max_features = max_features\n",
        "embedding_dim = 64\n",
        "cnn_model(drop_out=0.7, filter_one=32, filter_two=64,last_dense=64, padding='same',learning_rate=1e-6, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4426a6",
      "metadata": {
        "id": "bd4426a6"
      },
      "outputs": [],
      "source": [
        "# Create KerasClassifier model\n",
        "# Then pass the cnn_model function to the build_fn argument when constructing the KerasClassifier class.\n",
        "\n",
        "estimator = KerasClassifier(build_fn=cnn_model, kernel_size=5, epochs=10, batch_size=100, verbose=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a927745",
      "metadata": {
        "id": "9a927745"
      },
      "source": [
        "The batch size in iterative gradient descent is the number of patterns shown to the network before the weights are updated.\n",
        "It is also an optimization in the training of the network, defining how many patterns to read at a time and keep in memory.\n",
        "\n",
        "The number of epochs is the number of times that the entire training dataset is shown to the network during training.\n",
        "Some networks are sensitive to the batch size, such as LSTM, RNN and CNN.\n",
        "\n",
        "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "    \n",
        "    \n",
        "We would like to fine-tune these hyperparameters: fileters, dropout_rate,number of epochs,batch_size,padding and dense_layer_size.\n",
        "\n",
        "These parameters must be defined in the signature of cnn_model() function with default parameters.\n",
        "\n",
        "https://medium.com/@am.benatmane/keras-hyperparameter-tuning-using-sklearn-pipelines-grid-search-with-cross-validation-ccfc74b0ce9f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06fa662",
      "metadata": {
        "id": "a06fa662"
      },
      "outputs": [],
      "source": [
        "# Define the most relevant grid search parameters\n",
        "# A dictionary of hyperparameters to evaluate in the param_grid argument.\n",
        "# This is a map of the model parameter name and an array of values to try.\n",
        "\n",
        "param_grid = {\n",
        "    'filter_one':[32,64,128],\n",
        "    'epochs': [10,20,40,60],\n",
        "    'last_dense':[32,64,128],\n",
        "    'batch_size':[32,64,128],\n",
        "    'drop_out':[0.3, 0.4, 0.5],\n",
        "    'padding':['same','valid']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fafce49",
      "metadata": {
        "id": "4fafce49"
      },
      "source": [
        "1. estimator : Pass the model instance for which you want to check the hyperparameters.\n",
        "2.params_grid: the dictionary object that holds the hyperparameters you want to try\n",
        "3.scoring: evaluation metric that you want to use, you can simply pass a valid string/ object of evaluation metric\n",
        "4.cv: number of cross-validation you have to try for each selected set of hyperparameters\n",
        "5.verbose: you can set it to 1 to get the detailed print out while you fit the data to GridSearchCV\n",
        "6.n_jobs: number of processes you wish to run in parallel for this task if it -1 it will use all available processors.\n",
        "    \n",
        "https://www.mygreatlearning.com/blog/gridsearchcv/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e42b89b",
      "metadata": {
        "id": "1e42b89b"
      },
      "outputs": [],
      "source": [
        "# Conduct grid search with Kfold cross validation\n",
        "# We use Kfold cross validation to check how well our model is able to generalize the unseen data\n",
        "#Grid search is a model hyperparameter optimization technique.\n",
        "# By default, accuracy is the score that is optimized,\n",
        "# but other scores can be specified in the score argument of the GridSearchCV constructor.\n",
        "#By default, the grid search will only use one thread.\n",
        "# By setting the n_jobs argument in the GridSearchCV constructor to -1, the process will use all core processors on your machine.\n",
        "# Depending on your Keras backend, this may interfere with the main neural network training process.\n",
        "\n",
        "grid = GridSearchCV(estimator=estimator,\n",
        "                    n_jobs=-1,\n",
        "                    verbose=2,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy','precision_macro','recall_macro'],\n",
        "                    refit='precision_macro',\n",
        "                    cv=5,\n",
        "                    param_grid=param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61cae71",
      "metadata": {
        "id": "b61cae71"
      },
      "source": [
        "sklearn.model_selection.GridSearchCV\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07b7340",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "f07b7340",
        "outputId": "e1523cdb-bfd7-4fd0-833e-0a78996db2a0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-05309ebcccaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  access the outcome of the grid search in the result object returned from grid.fit().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "#  access the outcome of the grid search in the result object returned from grid.fit().\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train, verbose=2)\n",
        "\n",
        "# summarize results\n",
        "# The best_score_ member provides access to the best score observed during the optimization procedure\n",
        "# and the best_params_ describes the combination of parameters that achieved the best results\n",
        "\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3b0fac",
      "metadata": {
        "id": "ae3b0fac"
      },
      "outputs": [],
      "source": [
        "def run_experiments():\n",
        "    # grid search\n",
        "    drop_outs = (0.3,0.4,0.5,0.6, 0.7)\n",
        "    filters_one = (32, 64, 128,256)\n",
        "    filters_two = (32, 64, 128,256)\n",
        "    last_dense_layers = (32, 64, 128,256)\n",
        "    paddings = ('same', 'valid')\n",
        "\n",
        "    results = []\n",
        "    for drop_out in drop_outs:\n",
        "        for filter_one in filters_one[:-1]:\n",
        "            for filter_two in filters_two:\n",
        "                for last_dense in last_dense_layers:\n",
        "                    for padding in paddings:\n",
        "                        res = cnn_bilstm_model(drop_out, filter_one, filter_two, last_dense, padding,num_epochs=50)\n",
        "                        #res = 'running ...'\n",
        "                        results.append({'drop_out': drop_out,\n",
        "                                   'filter_one': filter_one,\n",
        "                                   'filter_two': filter_two,\n",
        "                                    'last_dense': last_dense,\n",
        "                                    'padding': padding,\n",
        "                                    'history': res})\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fdf0547",
      "metadata": {
        "id": "5fdf0547",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#r = run_experiments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc1632d",
      "metadata": {
        "id": "8dc1632d"
      },
      "outputs": [],
      "source": [
        "# Combination of CNN and BI-LSTM models\n",
        "\n",
        "def cnn_bilstm_model(drop_out, filter_one, filter_two, last_dense, padding, num_epochs):\n",
        "    # create a CNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
        "        tf.keras.layers.Embedding(max_features+2,embedding_dim,input_shape=(500,)),\n",
        "\n",
        "        # use ReLU in place of tanh function since they are very good alternatives of each other\n",
        "\n",
        "        tf.keras.layers.Conv1D(filters=filter_one, kernel_size=3, padding=padding, activation='relu'),\n",
        "        tf.keras.layers.MaxPool1D(pool_size=4),\n",
        "\n",
        "        # During the training of our model, we randomly cause some of the neurons to be excluded\n",
        "        # from the neural network (i.e. drop out) at each step with a fixed probability.\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "\n",
        "        tf.keras.layers.Conv1D(filters=filter_two, kernel_size=3, padding=padding, activation='relu'),\n",
        "        tf.keras.layers.MaxPool1D(pool_size=4),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "\n",
        "\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "        tf.keras.layers.Dropout(drop_out),\n",
        "        tf.keras.layers.Dense(last_dense, activation='relu'), #check with and without this layer\n",
        "\n",
        "        # Add a Dense layer with 3 units and softmax activation.\n",
        "        # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "    # Decide a model architecture, this is the number of hidden layers and activation functions, etc.\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    plot_model(model, to_file='./CNN-BiLSTM_model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "    #history = model.fit(X_train, y_train, epochs=num_epochs,validation_data=(X_test, y_test),callbacks=[es], verbose=0)\n",
        "\n",
        "\n",
        "    # simple early stopping\n",
        "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    # The ModelCheckpoint callback class allows you to define where to checkpoint the model weights,\n",
        "    # how the file should named and under what circumstances to make a checkpoint of the model.\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath='./best_CNN-BiLSTM_checkpoint.hdf5',\n",
        "                                   monitor='val_accuracy', verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=False,\n",
        "                                   mode='max',\n",
        "                                   save_freq=\"epoch\")\n",
        "\n",
        "    # Train the model for a given number of epochs(this is for training time, with the training dataset).\n",
        "    # Train our model to get all the paramters to the correct value to map our inputs to our outputs.\n",
        "    # The model is evaluated on the validation dataset at the end of each training epoch.\n",
        "    # The function is called ‚Äòfit‚Äô as we are fitting the parameters to the data.\n",
        "    history = model.fit(X_train, y_train, epochs=num_epochs,validation_data=(X_test, y_test), verbose=2,callbacks=[checkpointer])\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test data (this is for testing time, with the testing dataset)\n",
        "    # Returns the loss value & metrics values for the model in test mode.\n",
        "\n",
        "    print('\\n')\n",
        "    print(\"Evaluate on test data\",'\\n')\n",
        "    test_results = model.evaluate(X_test, y_test,batch_size=64)\n",
        "    print(\"Test Loss:\",test_results[0])\n",
        "    print(\"Test Accuracy:\",test_results[1])\n",
        "\n",
        "    # evaluate the model\n",
        "    #_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "    #_, test_acc =  model.evaluate(X_test, y_test, verbose=0)\n",
        "    #print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "    # Generate output predictions for the input samples(probabilities -the output of the last layer) on new data\n",
        "    # (this is for somewhere between training and testing time).\n",
        "    # Use this model to do some feed-forward passes to predict novel inputs.\n",
        "\n",
        "    print('\\n')\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"predictions shape:\", predictions.shape)\n",
        "    y_pred = (predictions)\n",
        "\n",
        "    #Creating a confusion matrix,which compares the y_test and y_pred\n",
        "    #Note The support column in classification_report is:\n",
        "    #the number of occurrences of each class in y_test.It shows testset distribution\n",
        "    # Plotting training and validation loss graph\n",
        "\n",
        "    results = pd.DataFrame(\n",
        "    confusion_matrix( y_test.argmax(axis=1), y_pred.argmax(axis=1)),\n",
        "    index=['D', 'L', 'Z'],\n",
        "    columns=['D', 'L', 'Z'])\n",
        "\n",
        "    print('-'*80,'\\n')\n",
        "    print('Confusion Matrix of Hybrid CNN and Bi-LSTM Model', '\\n')\n",
        "    print(results,'\\n')\n",
        "\n",
        "    print('Classification Report : ','\\n')\n",
        "    target_names = ['D-variety', 'L-variety', 'Z-variety']\n",
        "    print (classification_report(y_test.argmax(axis=1),y_pred.argmax(axis=1),target_names=target_names),'\\n')\n",
        "\n",
        "\n",
        "    # Plotting training and validation loss graph\n",
        "    print(\"Training and Validation Loss Graph\")\n",
        "    plt.plot(history.history['loss'], label='train loss')\n",
        "    plt.plot(history.history['val_loss'], label='val loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting training and validation Accuracy graph\n",
        "    plt.plot(history.history['accuracy'], label='train acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5c6603",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bc5c6603",
        "outputId": "80141c3f-34c1-4d5d-f3f5-630e6373b8ce",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 64)           1280128   \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 500, 128)          24704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 125, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 125, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 125, 64)           24640     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 31, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 31, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 1,358,659\n",
            "Trainable params: 1,358,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "200/200 - 11s - loss: 0.9992 - accuracy: 0.4410 - val_loss: 0.6793 - val_accuracy: 0.7467\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.74671, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 2/60\n",
            "200/200 - 6s - loss: 0.5233 - accuracy: 0.7891 - val_loss: 0.3622 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.74671 to 0.86270, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 3/60\n",
            "200/200 - 6s - loss: 0.4035 - accuracy: 0.8413 - val_loss: 0.3254 - val_accuracy: 0.8715\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.86270 to 0.87147, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 4/60\n",
            "200/200 - 6s - loss: 0.3419 - accuracy: 0.8683 - val_loss: 0.2862 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.87147 to 0.89342, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 5/60\n",
            "200/200 - 6s - loss: 0.2999 - accuracy: 0.8828 - val_loss: 0.2864 - val_accuracy: 0.8940\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.89342 to 0.89404, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 6/60\n",
            "200/200 - 6s - loss: 0.2749 - accuracy: 0.8974 - val_loss: 0.3181 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89404\n",
            "Epoch 7/60\n",
            "200/200 - 6s - loss: 0.2494 - accuracy: 0.9046 - val_loss: 0.2666 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.89404 to 0.89843, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 8/60\n",
            "200/200 - 6s - loss: 0.2337 - accuracy: 0.9117 - val_loss: 0.2419 - val_accuracy: 0.9041\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.89843 to 0.90408, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 9/60\n",
            "200/200 - 6s - loss: 0.2314 - accuracy: 0.9064 - val_loss: 0.2294 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90408 to 0.91348, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 10/60\n",
            "200/200 - 6s - loss: 0.2120 - accuracy: 0.9169 - val_loss: 0.2621 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91348\n",
            "Epoch 11/60\n",
            "200/200 - 6s - loss: 0.2010 - accuracy: 0.9221 - val_loss: 0.2319 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91348\n",
            "Epoch 12/60\n",
            "200/200 - 6s - loss: 0.1995 - accuracy: 0.9280 - val_loss: 0.2435 - val_accuracy: 0.9072\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91348\n",
            "Epoch 13/60\n",
            "200/200 - 6s - loss: 0.1839 - accuracy: 0.9261 - val_loss: 0.2694 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91348\n",
            "Epoch 14/60\n",
            "200/200 - 6s - loss: 0.1840 - accuracy: 0.9307 - val_loss: 0.2842 - val_accuracy: 0.8909\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91348\n",
            "Epoch 15/60\n",
            "200/200 - 6s - loss: 0.1688 - accuracy: 0.9333 - val_loss: 0.2182 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91348\n",
            "Epoch 16/60\n",
            "200/200 - 6s - loss: 0.1692 - accuracy: 0.9382 - val_loss: 0.2145 - val_accuracy: 0.9078\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91348\n",
            "Epoch 17/60\n",
            "200/200 - 6s - loss: 0.1631 - accuracy: 0.9343 - val_loss: 0.2159 - val_accuracy: 0.9141\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91348 to 0.91411, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 18/60\n",
            "200/200 - 6s - loss: 0.1497 - accuracy: 0.9456 - val_loss: 0.2462 - val_accuracy: 0.9016\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91411\n",
            "Epoch 19/60\n",
            "200/200 - 6s - loss: 0.1571 - accuracy: 0.9396 - val_loss: 0.2302 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91411\n",
            "Epoch 20/60\n",
            "200/200 - 6s - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.2425 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91411\n",
            "Epoch 21/60\n",
            "200/200 - 6s - loss: 0.1512 - accuracy: 0.9453 - val_loss: 0.2114 - val_accuracy: 0.9160\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.91411 to 0.91599, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 22/60\n",
            "200/200 - 6s - loss: 0.1449 - accuracy: 0.9449 - val_loss: 0.2366 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91599\n",
            "Epoch 23/60\n",
            "200/200 - 6s - loss: 0.1417 - accuracy: 0.9470 - val_loss: 0.2231 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91599\n",
            "Epoch 24/60\n",
            "200/200 - 6s - loss: 0.1385 - accuracy: 0.9476 - val_loss: 0.2175 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.91599 to 0.91787, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 25/60\n",
            "200/200 - 6s - loss: 0.1346 - accuracy: 0.9511 - val_loss: 0.2584 - val_accuracy: 0.9022\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91787\n",
            "Epoch 26/60\n",
            "200/200 - 6s - loss: 0.1387 - accuracy: 0.9497 - val_loss: 0.2239 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91787\n",
            "Epoch 27/60\n",
            "200/200 - 6s - loss: 0.1385 - accuracy: 0.9482 - val_loss: 0.2374 - val_accuracy: 0.9129\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91787\n",
            "Epoch 28/60\n",
            "200/200 - 6s - loss: 0.1346 - accuracy: 0.9495 - val_loss: 0.2143 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91787\n",
            "Epoch 29/60\n",
            "200/200 - 6s - loss: 0.1262 - accuracy: 0.9514 - val_loss: 0.2697 - val_accuracy: 0.9060\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91787\n",
            "Epoch 30/60\n",
            "200/200 - 6s - loss: 0.1248 - accuracy: 0.9534 - val_loss: 0.2369 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91787\n",
            "Epoch 31/60\n",
            "200/200 - 6s - loss: 0.1212 - accuracy: 0.9533 - val_loss: 0.2443 - val_accuracy: 0.9066\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91787\n",
            "Epoch 32/60\n",
            "200/200 - 6s - loss: 0.1153 - accuracy: 0.9562 - val_loss: 0.2234 - val_accuracy: 0.9141\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91787\n",
            "Epoch 33/60\n",
            "200/200 - 6s - loss: 0.1168 - accuracy: 0.9570 - val_loss: 0.2503 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91787\n",
            "Epoch 34/60\n",
            "200/200 - 6s - loss: 0.1197 - accuracy: 0.9550 - val_loss: 0.2569 - val_accuracy: 0.9053\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91787\n",
            "Epoch 35/60\n",
            "200/200 - 6s - loss: 0.1196 - accuracy: 0.9525 - val_loss: 0.2577 - val_accuracy: 0.9047\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91787\n",
            "Epoch 36/60\n",
            "200/200 - 6s - loss: 0.1131 - accuracy: 0.9578 - val_loss: 0.2415 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91787\n",
            "Epoch 37/60\n",
            "200/200 - 6s - loss: 0.1205 - accuracy: 0.9540 - val_loss: 0.2497 - val_accuracy: 0.9028\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91787\n",
            "Epoch 38/60\n",
            "200/200 - 6s - loss: 0.1158 - accuracy: 0.9588 - val_loss: 0.2291 - val_accuracy: 0.9129\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91787\n",
            "Epoch 39/60\n",
            "200/200 - 6s - loss: 0.1128 - accuracy: 0.9580 - val_loss: 0.2552 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91787\n",
            "Epoch 40/60\n",
            "200/200 - 6s - loss: 0.1082 - accuracy: 0.9591 - val_loss: 0.2474 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91787\n",
            "Epoch 41/60\n",
            "200/200 - 6s - loss: 0.1135 - accuracy: 0.9580 - val_loss: 0.2491 - val_accuracy: 0.9179\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91787\n",
            "Epoch 42/60\n",
            "200/200 - 6s - loss: 0.1110 - accuracy: 0.9597 - val_loss: 0.2208 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91787\n",
            "Epoch 43/60\n",
            "200/200 - 6s - loss: 0.1022 - accuracy: 0.9635 - val_loss: 0.2336 - val_accuracy: 0.9235\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.91787 to 0.92351, saving model to ./best_CNN-BiLSTM_checkpoint.hdf5\n",
            "Epoch 44/60\n",
            "200/200 - 6s - loss: 0.0967 - accuracy: 0.9625 - val_loss: 0.2576 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.92351\n",
            "Epoch 45/60\n",
            "200/200 - 6s - loss: 0.1065 - accuracy: 0.9638 - val_loss: 0.2547 - val_accuracy: 0.9072\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.92351\n",
            "Epoch 46/60\n",
            "200/200 - 6s - loss: 0.0966 - accuracy: 0.9624 - val_loss: 0.2569 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.92351\n",
            "Epoch 47/60\n",
            "200/200 - 6s - loss: 0.1082 - accuracy: 0.9606 - val_loss: 0.2439 - val_accuracy: 0.9103\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.92351\n",
            "Epoch 48/60\n",
            "200/200 - 6s - loss: 0.1004 - accuracy: 0.9625 - val_loss: 0.2648 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.92351\n",
            "Epoch 49/60\n",
            "200/200 - 6s - loss: 0.1074 - accuracy: 0.9598 - val_loss: 0.2381 - val_accuracy: 0.9147\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92351\n",
            "Epoch 50/60\n",
            "200/200 - 6s - loss: 0.0954 - accuracy: 0.9655 - val_loss: 0.2500 - val_accuracy: 0.9116\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92351\n",
            "Epoch 51/60\n",
            "200/200 - 6s - loss: 0.0889 - accuracy: 0.9691 - val_loss: 0.2612 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.92351\n",
            "Epoch 52/60\n",
            "200/200 - 6s - loss: 0.1000 - accuracy: 0.9639 - val_loss: 0.2423 - val_accuracy: 0.9135\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.92351\n",
            "Epoch 53/60\n",
            "200/200 - 6s - loss: 0.0983 - accuracy: 0.9657 - val_loss: 0.2310 - val_accuracy: 0.9078\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92351\n",
            "Epoch 54/60\n",
            "200/200 - 6s - loss: 0.0961 - accuracy: 0.9647 - val_loss: 0.2346 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92351\n",
            "Epoch 55/60\n",
            "200/200 - 6s - loss: 0.0945 - accuracy: 0.9650 - val_loss: 0.2478 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92351\n",
            "Epoch 56/60\n",
            "200/200 - 6s - loss: 0.1046 - accuracy: 0.9638 - val_loss: 0.2214 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92351\n",
            "Epoch 57/60\n",
            "200/200 - 6s - loss: 0.0933 - accuracy: 0.9675 - val_loss: 0.2273 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92351\n",
            "Epoch 58/60\n",
            "200/200 - 6s - loss: 0.0895 - accuracy: 0.9671 - val_loss: 0.2279 - val_accuracy: 0.9166\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.92351\n",
            "Epoch 59/60\n",
            "200/200 - 6s - loss: 0.0915 - accuracy: 0.9657 - val_loss: 0.2439 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92351\n",
            "Epoch 60/60\n",
            "200/200 - 6s - loss: 0.1000 - accuracy: 0.9635 - val_loss: 0.2260 - val_accuracy: 0.9141\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92351\n",
            "\n",
            "\n",
            "Evaluate on test data \n",
            "\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 0.2260 - accuracy: 0.9141\n",
            "Test Loss: 0.22599178552627563\n",
            "Test Accuracy: 0.9141066074371338\n",
            "\n",
            "\n",
            "predictions shape: (1595, 3)\n",
            "-------------------------------------------------------------------------------- \n",
            "\n",
            "Confusion Matrix of Hybrid CNN and Bi-LSTM Model \n",
            "\n",
            "     D    L    Z\n",
            "D  549   25    2\n",
            "L   30  441   30\n",
            "Z   13   37  468 \n",
            "\n",
            "Classification Report :  \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   D-variety       0.93      0.95      0.94       576\n",
            "   L-variety       0.88      0.88      0.88       501\n",
            "   Z-variety       0.94      0.90      0.92       518\n",
            "\n",
            "    accuracy                           0.91      1595\n",
            "   macro avg       0.91      0.91      0.91      1595\n",
            "weighted avg       0.91      0.91      0.91      1595\n",
            " \n",
            "\n",
            "Training and Validation Loss Graph\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': [0.4410288631916046,\n",
              "  0.7890527248382568,\n",
              "  0.8412798047065735,\n",
              "  0.8682559728622437,\n",
              "  0.8828418850898743,\n",
              "  0.8974278569221497,\n",
              "  0.9046424031257629,\n",
              "  0.9117001295089722,\n",
              "  0.9063675999641418,\n",
              "  0.9168757796287537,\n",
              "  0.9220514297485352,\n",
              "  0.9280112981796265,\n",
              "  0.9261292219161987,\n",
              "  0.9306775331497192,\n",
              "  0.933343768119812,\n",
              "  0.9382057785987854,\n",
              "  0.9342848062515259,\n",
              "  0.9455771446228027,\n",
              "  0.9396173357963562,\n",
              "  0.9460476636886597,\n",
              "  0.9452635049819946,\n",
              "  0.9449498057365417,\n",
              "  0.9469887018203735,\n",
              "  0.9476160407066345,\n",
              "  0.9510664939880371,\n",
              "  0.9496549367904663,\n",
              "  0.9482434391975403,\n",
              "  0.9494981169700623,\n",
              "  0.95138019323349,\n",
              "  0.9534190893173218,\n",
              "  0.953262209892273,\n",
              "  0.9562421441078186,\n",
              "  0.9570263624191284,\n",
              "  0.9549874663352966,\n",
              "  0.9524780511856079,\n",
              "  0.9578105211257935,\n",
              "  0.9540464282035828,\n",
              "  0.9587515592575073,\n",
              "  0.9579674005508423,\n",
              "  0.9590652585029602,\n",
              "  0.9579674005508423,\n",
              "  0.9596925973892212,\n",
              "  0.9634566903114319,\n",
              "  0.9625157117843628,\n",
              "  0.9637703895568848,\n",
              "  0.962358832359314,\n",
              "  0.9606336355209351,\n",
              "  0.9625157117843628,\n",
              "  0.9598494172096252,\n",
              "  0.9654955863952637,\n",
              "  0.9691028594970703,\n",
              "  0.9639272093772888,\n",
              "  0.9656524658203125,\n",
              "  0.9647114276885986,\n",
              "  0.9650250673294067,\n",
              "  0.9637703895568848,\n",
              "  0.9675344824790955,\n",
              "  0.9670639634132385,\n",
              "  0.9656524658203125,\n",
              "  0.9634566903114319],\n",
              " 'loss': [0.999164342880249,\n",
              "  0.5233393311500549,\n",
              "  0.4034651219844818,\n",
              "  0.3418709933757782,\n",
              "  0.2998908758163452,\n",
              "  0.2749468982219696,\n",
              "  0.24938344955444336,\n",
              "  0.23370009660720825,\n",
              "  0.2314036339521408,\n",
              "  0.21202227473258972,\n",
              "  0.20096252858638763,\n",
              "  0.19954843819141388,\n",
              "  0.18387313187122345,\n",
              "  0.18396995961666107,\n",
              "  0.16875477135181427,\n",
              "  0.16917115449905396,\n",
              "  0.1630970537662506,\n",
              "  0.1496993601322174,\n",
              "  0.15711387991905212,\n",
              "  0.14691714942455292,\n",
              "  0.1511925458908081,\n",
              "  0.14490902423858643,\n",
              "  0.14169029891490936,\n",
              "  0.1384851336479187,\n",
              "  0.13456973433494568,\n",
              "  0.1386624127626419,\n",
              "  0.1384800225496292,\n",
              "  0.1346110999584198,\n",
              "  0.12622499465942383,\n",
              "  0.124842070043087,\n",
              "  0.12119446694850922,\n",
              "  0.11525512486696243,\n",
              "  0.11683028936386108,\n",
              "  0.11971054971218109,\n",
              "  0.11958503723144531,\n",
              "  0.11311528086662292,\n",
              "  0.1205110177397728,\n",
              "  0.11583086848258972,\n",
              "  0.1127503514289856,\n",
              "  0.10819729417562485,\n",
              "  0.11348997801542282,\n",
              "  0.11104413121938705,\n",
              "  0.10219766199588776,\n",
              "  0.0967339351773262,\n",
              "  0.10646392405033112,\n",
              "  0.09657905250787735,\n",
              "  0.1081632748246193,\n",
              "  0.10041001439094543,\n",
              "  0.10737277567386627,\n",
              "  0.09535398334264755,\n",
              "  0.08888369053602219,\n",
              "  0.10002553462982178,\n",
              "  0.0982721820473671,\n",
              "  0.09605865925550461,\n",
              "  0.0945347473025322,\n",
              "  0.10461331903934479,\n",
              "  0.09327506273984909,\n",
              "  0.08946114033460617,\n",
              "  0.0914975106716156,\n",
              "  0.09998396039009094],\n",
              " 'val_accuracy': [0.7467084527015686,\n",
              "  0.8626959323883057,\n",
              "  0.8714733719825745,\n",
              "  0.8934169411659241,\n",
              "  0.8940438628196716,\n",
              "  0.8733542561531067,\n",
              "  0.8984326124191284,\n",
              "  0.9040752053260803,\n",
              "  0.9134796261787415,\n",
              "  0.8952978253364563,\n",
              "  0.9134796261787415,\n",
              "  0.9072100520133972,\n",
              "  0.8915360569953918,\n",
              "  0.8909090757369995,\n",
              "  0.9134796261787415,\n",
              "  0.9078369736671448,\n",
              "  0.9141066074371338,\n",
              "  0.9015673995018005,\n",
              "  0.9034482836723328,\n",
              "  0.9134796261787415,\n",
              "  0.9159874320030212,\n",
              "  0.9134796261787415,\n",
              "  0.9122257232666016,\n",
              "  0.9178683161735535,\n",
              "  0.9021943807601929,\n",
              "  0.9134796261787415,\n",
              "  0.9128526449203491,\n",
              "  0.9166144132614136,\n",
              "  0.9059560894966125,\n",
              "  0.9153605103492737,\n",
              "  0.9065830707550049,\n",
              "  0.9141066074371338,\n",
              "  0.909717857837677,\n",
              "  0.905329167842865,\n",
              "  0.9047021865844727,\n",
              "  0.9166144132614136,\n",
              "  0.9028213024139404,\n",
              "  0.9128526449203491,\n",
              "  0.909717857837677,\n",
              "  0.9090909361839294,\n",
              "  0.9178683161735535,\n",
              "  0.9172413945198059,\n",
              "  0.9235109686851501,\n",
              "  0.9090909361839294,\n",
              "  0.9072100520133972,\n",
              "  0.9122257232666016,\n",
              "  0.9103448390960693,\n",
              "  0.909717857837677,\n",
              "  0.9147335290908813,\n",
              "  0.9115987420082092,\n",
              "  0.9122257232666016,\n",
              "  0.9134796261787415,\n",
              "  0.9078369736671448,\n",
              "  0.9090909361839294,\n",
              "  0.9122257232666016,\n",
              "  0.9210031628608704,\n",
              "  0.9122257232666016,\n",
              "  0.9166144132614136,\n",
              "  0.909717857837677,\n",
              "  0.9141066074371338],\n",
              " 'val_loss': [0.6793213486671448,\n",
              "  0.36222413182258606,\n",
              "  0.3254443407058716,\n",
              "  0.286189466714859,\n",
              "  0.2864435315132141,\n",
              "  0.31813082098960876,\n",
              "  0.266634076833725,\n",
              "  0.2419116050004959,\n",
              "  0.22937221825122833,\n",
              "  0.26212188601493835,\n",
              "  0.2319236397743225,\n",
              "  0.24353894591331482,\n",
              "  0.2693859040737152,\n",
              "  0.28416574001312256,\n",
              "  0.21815364062786102,\n",
              "  0.214485764503479,\n",
              "  0.21591287851333618,\n",
              "  0.24615640938282013,\n",
              "  0.2302233725786209,\n",
              "  0.24249613285064697,\n",
              "  0.21142174303531647,\n",
              "  0.2366357445716858,\n",
              "  0.2230805903673172,\n",
              "  0.21748414635658264,\n",
              "  0.25836509466171265,\n",
              "  0.2238718867301941,\n",
              "  0.23742149770259857,\n",
              "  0.21426843106746674,\n",
              "  0.2697219252586365,\n",
              "  0.23687952756881714,\n",
              "  0.2442694455385208,\n",
              "  0.2234451174736023,\n",
              "  0.2502729296684265,\n",
              "  0.2568618059158325,\n",
              "  0.257720947265625,\n",
              "  0.24150915443897247,\n",
              "  0.2496858835220337,\n",
              "  0.22914382815361023,\n",
              "  0.2551896274089813,\n",
              "  0.24741147458553314,\n",
              "  0.2491096556186676,\n",
              "  0.220829039812088,\n",
              "  0.23360344767570496,\n",
              "  0.2576468586921692,\n",
              "  0.2546921968460083,\n",
              "  0.25693121552467346,\n",
              "  0.24390791356563568,\n",
              "  0.2647567093372345,\n",
              "  0.23812837898731232,\n",
              "  0.25002846121788025,\n",
              "  0.26117005944252014,\n",
              "  0.24226699769496918,\n",
              "  0.2309897094964981,\n",
              "  0.2345723956823349,\n",
              "  0.24781319499015808,\n",
              "  0.22136245667934418,\n",
              "  0.2273281365633011,\n",
              "  0.2279452383518219,\n",
              "  0.2438688725233078,\n",
              "  0.22599177062511444]}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "max_features = max_features\n",
        "embedding_dim = 64\n",
        "cnn_bilstm_model(drop_out=0.5, filter_one=128, filter_two=64, last_dense=64, padding='same', num_epochs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8h2aRV2RK9O",
      "metadata": {
        "id": "a8h2aRV2RK9O"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/gdrive/MyDrive/ColabNotebooks/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IqEKWi-AN5aV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqEKWi-AN5aV",
        "outputId": "5d5729bc-e787-4b00-d323-f6b85822d130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " all_source111.tsv     'Multi-Class Text Classification with LSTM TDI  .ipynb'\n",
            " DL-char-ngrams.ipynb  'Text Classification with LSTM TDI .ipynb'\n"
          ]
        }
      ],
      "source": [
        "!ls /content/gdrive/MyDrive/ColabNotebooks/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}