{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification with scikit learn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Linear SVM\", \"Neural Net\", \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fin):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(fin) as f:\n",
    "        for line in f:\n",
    "            label, feats = line.rstrip('\\n').split('\\t')\n",
    "            #print(feats)\n",
    "            feats = [int(i) for i in feats.split()]\n",
    "            X.append(feats)\n",
    "            y.append(label)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('ngram-128', load_data('../data/ngram_128.tsv')),\n",
    "            ('ngram-200', load_data('../data/ngram_200.tsv')),\n",
    "            ('ngram-300', load_data('../data/ngram_300.tsv'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "ngram-128\n",
      "Linear SVM\n",
      "0.5238095238095238\n",
      "precision recall f1\n",
      "(0.6987654320987655, 0.5946275946275946, 0.5155828639699607, None)\n",
      "\n",
      "Neural Net\n",
      "0.5714285714285714\n",
      "precision recall f1\n",
      "(0.5565323565323566, 0.5427350427350427, 0.5343915343915344, None)\n",
      "\n",
      "Naive Bayes\n",
      "0.6428571428571429\n",
      "precision recall f1\n",
      "(0.6813765182186234, 0.7032967032967031, 0.6357235325692274, None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ngram-200\n",
      "Linear SVM\n",
      "0.5476190476190477\n",
      "precision recall f1\n",
      "(0.7136752136752137, 0.6202686202686203, 0.5473551050301274, None)\n",
      "\n",
      "Neural Net\n",
      "0.6428571428571429\n",
      "precision recall f1\n",
      "(0.611489898989899, 0.6098901098901099, 0.6010973379394433, None)\n",
      "\n",
      "Naive Bayes\n",
      "0.7142857142857143\n",
      "precision recall f1\n",
      "(0.7555555555555555, 0.7606837606837606, 0.7068117068117069, None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ngram-300\n",
      "Linear SVM\n",
      "0.5952380952380952\n",
      "precision recall f1\n",
      "(0.7733333333333334, 0.6715506715506715, 0.6100032583903552, None)\n",
      "\n",
      "Neural Net\n",
      "0.6666666666666666\n",
      "precision recall f1\n",
      "(0.6297657952069716, 0.6355311355311355, 0.6269171915590191, None)\n",
      "\n",
      "Naive Bayes\n",
      "0.7380952380952381\n",
      "precision recall f1\n",
      "(0.7447619047619046, 0.6991758241758242, 0.714975845410628, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for ds_cnt, (name, ds) in enumerate(datasets):\n",
    "    print('-'*80)\n",
    "    print(name)\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(name)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(score)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "        print('precision', 'recall', 'f1')\n",
    "        print(prf)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Scikit Learn Classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
